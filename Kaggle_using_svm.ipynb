{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digits - Classification Using SVM\n",
    "\n",
    "In this notebook, we'll explore the popular MNIST dataset and build an SVM model to classify handwritten digits. <a href='https://www.kaggle.com/c/digit-recognizer/data'>Here is a detailed description of the dataset.</a>\n",
    "\n",
    "I will divide the analysis into the following parts:\n",
    "- Data understanding and cleaning\n",
    "- Data preparation for model building\n",
    "- Building an SVM model - hyperparameter tuning, model evaluation etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding and Cleaning\n",
    " \n",
    " Let's understand the dataset and see if it needs some cleaning etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n"
     ]
    }
   ],
   "source": [
    "# read the dataset\n",
    "digits = pd.read_csv(r\"C:\\Users\\Admin\\train.csv\")\n",
    "digits.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# head\n",
    "digits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero = digits.iloc[1, 1:]\n",
    "zero.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29908198358>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "zero = zero.values.reshape(28, 28)\n",
    "plt.imshow(zero, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Side note: Indexing Recall ####\n",
    "`list =    [0, 4, 2, 10, 22, 101, 10]` <br>\n",
    "`indices = [0, 1, 2, 3, ...,        ]` <br>\n",
    "`reverse = [-n           -3  -2   -1]` <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0  13  86 250 254 254 254 254 217 246 151  32   0   0   0   0]\n",
      " [  0   0  16 179 254 254 254 254 254 254 254 254 254 231  54  15   0   0]\n",
      " [  0   0  72 254 254 254 254 254 254 254 254 254 254 254 254 104   0   0]\n",
      " [  0  61 191 254 254 254 254 254 109  83 199 254 254 254 254 243  85   0]\n",
      " [  0 172 254 254 254 202 147 147  45   0  11  29 200 254 254 254 171   0]\n",
      " [  1 174 254 254  89  67   0   0   0   0   0   0 128 252 254 254 212  76]\n",
      " [ 47 254 254 254  29   0   0   0   0   0   0   0   0  83 254 254 254 153]\n",
      " [ 80 254 254 240  24   0   0   0   0   0   0   0   0  25 240 254 254 153]\n",
      " [ 64 254 254 186   7   0   0   0   0   0   0   0   0   0 166 254 254 224]\n",
      " [232 254 254 254  29   0   0   0   0   0   0   0   0   0  75 254 254 254]\n",
      " [254 254 254 254  29   0   0   0   0   0   0   0   0   0  48 254 254 254]\n",
      " [163 254 254 254  29   0   0   0   0   0   0   0   0   0  48 254 254 254]\n",
      " [ 94 254 254 254 200  12   0   0   0   0   0   0   0  16 209 254 254 150]\n",
      " [ 15 206 254 254 254 202  66   0   0   0   0   0  21 161 254 254 245  31]\n",
      " [  0  60 212 254 254 254 194  48  48  34  41  48 209 254 254 254 171   0]\n",
      " [  0   0  86 243 254 254 254 254 254 233 243 254 254 254 254 254  86   0]\n",
      " [  0   0   0 114 254 254 254 254 254 254 254 254 254 254 239  86  11   0]\n",
      " [  0   0   0  13 182 254 254 254 254 254 254 254 254 243  70   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# visualise the array\n",
    "print(zero[5:-5, 5:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarise the counts of 'label' to see how many labels of each digit are present\n",
    "digits.label.astype('category').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11.15\n",
       "7    10.48\n",
       "3    10.36\n",
       "9     9.97\n",
       "2     9.95\n",
       "6     9.85\n",
       "0     9.84\n",
       "4     9.70\n",
       "8     9.67\n",
       "5     9.04\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarise count in terms of percentage \n",
    "100*(round(digits.label.astype('category').value_counts()/len(digits.index), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, each digit/label has an approximately 9%-11% fraction in the dataset and the **dataset is balanced**. This is an important factor in considering the choices of models to be used, especially SVM, since **SVMs rarely perform well on imbalanced data** (think about why that might be the case).\n",
    "\n",
    "Let's quickly look at missing values, if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label       0\n",
       "pixel0      0\n",
       "pixel1      0\n",
       "pixel2      0\n",
       "pixel3      0\n",
       "           ..\n",
       "pixel779    0\n",
       "pixel780    0\n",
       "pixel781    0\n",
       "pixel782    0\n",
       "pixel783    0\n",
       "Length: 785, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values - there are none\n",
    "digits.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, let's look at the average values of each column, since we'll need to do some rescaling in case the ranges vary too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.456643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.887730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
       "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\n",
       "count  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \n",
       "mean       0.0      0.0      0.0  ...      0.219286      0.117095   \n",
       "std        0.0      0.0      0.0  ...      6.312890      4.633819   \n",
       "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
       "\n",
       "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
       "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
       "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
       "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
       "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "25%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "75%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  \n",
       "count   42000.0   42000.0   42000.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average values/distributions of features\n",
    "description = digits.describe()\n",
    "description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the max value of the mean and maximum values of some features (pixels) is 139, 255 etc., whereas most features lie in much lower ranges  (look at description of pixel 0, pixel 1 etc. above).\n",
    "\n",
    "Thus, it seems like a good idea to rescale the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for Model Building\n",
    "\n",
    "Let's now prepare the dataset for building the model. We'll only use a fraction of the data else training will take a long time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4200, 784)\n",
      "(37800, 784)\n",
      "(4200,)\n",
      "(37800,)\n"
     ]
    }
   ],
   "source": [
    "# Creating training and test sets\n",
    "# Splitting the data into train and test\n",
    "X = digits.iloc[:, 1:]\n",
    "Y = digits.iloc[:, 0]\n",
    "\n",
    "# Rescaling the features\n",
    "from sklearn.preprocessing import scale\n",
    "X = scale(X)\n",
    "\n",
    "# train test split with train_size=10% and test size=90%\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.10, random_state=101)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "Let's now build the model and tune the hyperparameters. Let's start with a **linear model** first.\n",
    "\n",
    "### Linear SVM\n",
    "\n",
    "Let's first try building a linear SVM model (i.e. a linear kernel). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "# an initial SVM model with linear kernel   \n",
    "svm_linear = svm.SVC(kernel='linear')\n",
    "\n",
    "# fit\n",
    "svm_linear.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 0, 0, 1, 9, 1, 5, 0, 6], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict\n",
    "predictions = svm_linear.predict(x_test)\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3615,    0,   12,    8,    8,   28,   28,    5,    9,    2],\n",
       "       [   0, 4089,   16,   23,    9,    3,    3,   13,   25,    4],\n",
       "       [  54,   48, 3363,   64,   74,   13,   53,   52,   59,   10],\n",
       "       [  20,   28,  121, 3387,    8,  175,    5,   54,   58,   44],\n",
       "       [  12,   12,   26,    2, 3399,    7,   41,   41,    4,  158],\n",
       "       [  49,   42,   32,  177,   41, 2899,   54,   14,   82,   28],\n",
       "       [  36,   16,   55,    5,   34,   37, 3486,    3,   21,    0],\n",
       "       [   9,   27,   37,   22,   70,   10,    4, 3619,   14,  142],\n",
       "       [  26,   86,   71,  137,   24,  137,   29,   26, 3096,   33],\n",
       "       [  38,   11,   39,   26,  182,   19,    1,  207,   27, 3228]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation: accuracy\n",
    "# C(i, j) represents the number of points known to be in class i \n",
    "# but predicted to be in class j\n",
    "confusion = metrics.confusion_matrix(y_true = y_test, y_pred = predictions)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9042592592592592"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# measure accuracy\n",
    "metrics.accuracy_score(y_true=y_test, y_pred=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95      3715\n",
      "           1       0.94      0.98      0.96      4185\n",
      "           2       0.89      0.89      0.89      3790\n",
      "           3       0.88      0.87      0.87      3900\n",
      "           4       0.88      0.92      0.90      3702\n",
      "           5       0.87      0.85      0.86      3418\n",
      "           6       0.94      0.94      0.94      3693\n",
      "           7       0.90      0.92      0.91      3954\n",
      "           8       0.91      0.84      0.88      3665\n",
      "           9       0.88      0.85      0.87      3778\n",
      "\n",
      "    accuracy                           0.90     37800\n",
      "   macro avg       0.90      0.90      0.90     37800\n",
      "weighted avg       0.90      0.90      0.90     37800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# class-wise accuracy\n",
    "class_wise = metrics.classification_report(y_true=y_test, y_pred=predictions)\n",
    "print(class_wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run gc.collect() (garbage collect) to free up memory\n",
    "# else, since the dataset is large and SVM is computationally heavy,\n",
    "# it'll throw a memory error while training\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Linear SVM\n",
    "\n",
    "Let's now try a non-linear model with the RBF kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rbf kernel with other hyperparameters kept to default \n",
    "svm_rbf = svm.SVC(kernel='rbf')\n",
    "svm_rbf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9250793650793651\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predictions = svm_rbf.predict(x_test)\n",
    "\n",
    "# accuracy \n",
    "print(metrics.accuracy_score(y_true=y_test, y_pred=predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy achieved with a non-linear kernel is slightly higher than a linear one. Let's now do a grid search CV to tune the hyperparameters C and gamma.\n",
    "\n",
    "### Grid Search Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct (grid search) cross-validation to find the optimal values \n",
    "# of cost C and the choice of kernel\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'C':[1, 10, 100], \n",
    "             'gamma': [1e-2, 1e-3, 1e-4]}\n",
    "\n",
    "# instantiate a model \n",
    "svc_grid_search = svm.SVC(kernel=\"rbf\")\n",
    "\n",
    "# create a classifier to perform grid search\n",
    "clf = GridSearchCV(svc_grid_search, param_grid=parameters, scoring='accuracy')\n",
    "\n",
    "# fit\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.931037</td>\n",
       "      <td>0.845512</td>\n",
       "      <td>5.475331</td>\n",
       "      <td>0.069436</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.719048</td>\n",
       "      <td>0.759524</td>\n",
       "      <td>0.686905</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.726190</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.023450</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.490199</td>\n",
       "      <td>0.253660</td>\n",
       "      <td>3.662516</td>\n",
       "      <td>0.118019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.001}</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.921429</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.911905</td>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.918095</td>\n",
       "      <td>0.006709</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.351614</td>\n",
       "      <td>0.122691</td>\n",
       "      <td>4.702258</td>\n",
       "      <td>0.036330</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.0001}</td>\n",
       "      <td>0.876190</td>\n",
       "      <td>0.884524</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.873810</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.876905</td>\n",
       "      <td>0.006547</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.182875</td>\n",
       "      <td>0.463506</td>\n",
       "      <td>5.448946</td>\n",
       "      <td>0.024085</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.709524</td>\n",
       "      <td>0.746429</td>\n",
       "      <td>0.744048</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.021176</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.395284</td>\n",
       "      <td>0.127936</td>\n",
       "      <td>3.329322</td>\n",
       "      <td>0.028025</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001}</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.927381</td>\n",
       "      <td>0.915476</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.930952</td>\n",
       "      <td>0.925238</td>\n",
       "      <td>0.011076</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.033212</td>\n",
       "      <td>0.145929</td>\n",
       "      <td>3.064665</td>\n",
       "      <td>0.027852</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.0001}</td>\n",
       "      <td>0.921429</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.920238</td>\n",
       "      <td>0.915476</td>\n",
       "      <td>0.009066</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42.134794</td>\n",
       "      <td>0.402287</td>\n",
       "      <td>5.461026</td>\n",
       "      <td>0.031187</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01}</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.709524</td>\n",
       "      <td>0.746429</td>\n",
       "      <td>0.744048</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.021176</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.384607</td>\n",
       "      <td>0.152918</td>\n",
       "      <td>3.275457</td>\n",
       "      <td>0.088450</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001}</td>\n",
       "      <td>0.938095</td>\n",
       "      <td>0.929762</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.929762</td>\n",
       "      <td>0.924048</td>\n",
       "      <td>0.010999</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.946554</td>\n",
       "      <td>0.095632</td>\n",
       "      <td>2.570644</td>\n",
       "      <td>0.089542</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.0001}</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.920238</td>\n",
       "      <td>0.886905</td>\n",
       "      <td>0.890476</td>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.905952</td>\n",
       "      <td>0.015040</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0      41.931037      0.845512         5.475331        0.069436       1   \n",
       "1      13.490199      0.253660         3.662516        0.118019       1   \n",
       "2      19.351614      0.122691         4.702258        0.036330       1   \n",
       "3      42.182875      0.463506         5.448946        0.024085      10   \n",
       "4      11.395284      0.127936         3.329322        0.028025      10   \n",
       "5       9.033212      0.145929         3.064665        0.027852      10   \n",
       "6      42.134794      0.402287         5.461026        0.031187     100   \n",
       "7      11.384607      0.152918         3.275457        0.088450     100   \n",
       "8       6.946554      0.095632         2.570644        0.089542     100   \n",
       "\n",
       "  param_gamma                       params  split0_test_score  \\\n",
       "0        0.01      {'C': 1, 'gamma': 0.01}           0.719048   \n",
       "1       0.001     {'C': 1, 'gamma': 0.001}           0.925000   \n",
       "2      0.0001    {'C': 1, 'gamma': 0.0001}           0.876190   \n",
       "3        0.01     {'C': 10, 'gamma': 0.01}           0.733333   \n",
       "4       0.001    {'C': 10, 'gamma': 0.001}           0.941667   \n",
       "5      0.0001   {'C': 10, 'gamma': 0.0001}           0.921429   \n",
       "6        0.01    {'C': 100, 'gamma': 0.01}           0.733333   \n",
       "7       0.001   {'C': 100, 'gamma': 0.001}           0.938095   \n",
       "8      0.0001  {'C': 100, 'gamma': 0.0001}           0.908333   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.759524           0.686905           0.733333           0.726190   \n",
       "1           0.921429           0.908333           0.911905           0.923810   \n",
       "2           0.884524           0.866667           0.873810           0.883333   \n",
       "3           0.775000           0.709524           0.746429           0.744048   \n",
       "4           0.927381           0.915476           0.910714           0.930952   \n",
       "5           0.925000           0.900000           0.910714           0.920238   \n",
       "6           0.775000           0.709524           0.746429           0.744048   \n",
       "7           0.929762           0.914286           0.908333           0.929762   \n",
       "8           0.920238           0.886905           0.890476           0.923810   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.725000        0.023450                9  \n",
       "1         0.918095        0.006709                3  \n",
       "2         0.876905        0.006547                6  \n",
       "3         0.741667        0.021176                7  \n",
       "4         0.925238        0.011076                1  \n",
       "5         0.915476        0.009066                4  \n",
       "6         0.741667        0.021176                7  \n",
       "7         0.924048        0.010999                2  \n",
       "8         0.905952        0.015040                5  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results\n",
    "cv_results = pd.DataFrame(clf.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7kAAAGHCAYAAAB1SJU0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10de1e278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# converting C to numeric type for plotting on x-axis\n",
    "cv_results['param_C'] = cv_results['param_C'].astype('int')\n",
    "\n",
    "# # plotting\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "# subplot 1/3\n",
    "plt.subplot(131)\n",
    "gamma_01 = cv_results[cv_results['param_gamma']==0.01]\n",
    "\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_test_score\"])\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.01\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='lower right')\n",
    "plt.xscale('log')\n",
    "\n",
    "# subplot 2/3\n",
    "plt.subplot(132)\n",
    "gamma_001 = cv_results[cv_results['param_gamma']==0.001]\n",
    "\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_test_score\"])\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.001\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='lower right')\n",
    "plt.xscale('log')\n",
    "\n",
    "\n",
    "# subplot 3/3\n",
    "plt.subplot(133)\n",
    "gamma_0001 = cv_results[cv_results['param_gamma']==0.0001]\n",
    "\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_test_score\"])\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.0001\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='lower right')\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, we can observe that (from higher to lower gamma / left to right):\n",
    "- At very high gamma (0.01), the model is achieving 100% accuracy on the training data, though the test score is quite low (<75%). Thus, the model is overfitting.\n",
    "\n",
    "- At gamma=0.001, the training and test scores are comparable at around C=1, though the model starts to overfit at higher values of C\n",
    "\n",
    "- At gamma=0.0001, the model does not overfit till C=10 but starts showing signs at C=100. Also, the training and test scores are slightly lower than at gamma=0.001.\n",
    "\n",
    "Thus, it seems that the best combination is gamma=0.001 and C=1 (the plot in the middle), which gives the highest test accuracy (~92%) while avoiding overfitting.\n",
    "\n",
    "Let's now build the final model and see the performance on test data.\n",
    "\n",
    "### Final Model\n",
    "\n",
    "Let's now build the final model with chosen hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimal hyperparameters\n",
    "best_C = 1\n",
    "best_gamma = 0.001\n",
    "\n",
    "# model\n",
    "svm_final = svm.SVC(kernel='rbf', C=best_C, gamma=best_gamma)\n",
    "\n",
    "# fit\n",
    "svm_final.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "predictions = svm_final.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.924973544974 \n",
      "\n",
      "[[3587    0   10   10    5   15   50   12   25    1]\n",
      " [   0 4108   14   16    5    3    6   18   10    5]\n",
      " [  24   23 3407   65   44    5   36  123   54    9]\n",
      " [   4   21   86 3502    5   89   11   73   76   33]\n",
      " [   3   11   36    7 3450   13   23   43    6  110]\n",
      " [  20   29   14  114   18 3020   79   53   36   35]\n",
      " [  31   12   11    1   14   34 3521   44   25    0]\n",
      " [   4   28   27    8   36    7    1 3739    7   97]\n",
      " [  14   59   32   80   22   97   25   44 3251   41]\n",
      " [  23   13   13   50   98    7    0  176   19 3379]]\n"
     ]
    }
   ],
   "source": [
    "# evaluation: CM \n",
    "confusion = metrics.confusion_matrix(y_true = y_test, y_pred = predictions)\n",
    "\n",
    "# measure accuracy\n",
    "test_accuracy = metrics.accuracy_score(y_true=y_test, y_pred=predictions)\n",
    "\n",
    "print(test_accuracy, \"\\n\")\n",
    "print(confusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The final accuracy on test data is approx. 92%. Note that this can be significantly increased by using the entire training data of 42,000 images (I have used just 10% of that!). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
